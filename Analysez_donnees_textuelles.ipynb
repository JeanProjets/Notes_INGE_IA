{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6911e9e2",
   "metadata": {},
   "source": [
    "# Analysez vos données textuelles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35c9de40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/jb/.pyenv/versions/3.11.13/lib/python3.11/site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /home/jb/.pyenv/versions/3.11.13/lib/python3.11/site-packages (from pandas) (2.3.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/jb/.pyenv/versions/3.11.13/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/jb/.pyenv/versions/3.11.13/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/jb/.pyenv/versions/3.11.13/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/jb/.pyenv/versions/3.11.13/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97b89c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc23165",
   "metadata": {},
   "source": [
    "## Prétraitez les données textuelles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509b2a06",
   "metadata": {},
   "source": [
    "### Récupérer et explorer le corpus de texte"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189014c7",
   "metadata": {},
   "source": [
    "Un peu de vocabulaire :\n",
    "- corpus : ensemble de documents regroupés dans un optique ou une thématique précise\n",
    "- document : texte appartenant à un corpus, mais indépendant des autres textes. Peut-être consituté de plusieurs phrases ou plusieurs paragraphes\n",
    "- token : mot ou élément de ponctuation\n",
    "- vocabulaire : ensemble des tokens DISTINCTS présent dans le corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcc9ef7a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_all_sentences' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m db = \u001b[43mload_all_sentences\u001b[49m();\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mchargement de \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m vers dans la db\u001b[39m\u001b[33m'\u001b[39m.format(\u001b[38;5;28mlen\u001b[39m(db.keys())))\n",
      "\u001b[31mNameError\u001b[39m: name 'load_all_sentences' is not defined"
     ]
    }
   ],
   "source": [
    "db = load_all_sentences();\n",
    "print('chargement de {} vers dans la db'.format(len(db.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43bd5221",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'db' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcollections\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m defaultdict\n\u001b[32m      2\u001b[39m base_artistes = defaultdict(\u001b[38;5;28mset\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k,v \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdb\u001b[49m.iteritems():\n\u001b[32m      4\u001b[39m     base_artistes[v[\u001b[33m'\u001b[39m\u001b[33martistes\u001b[39m\u001b[33m'\u001b[39m]].add(k)\n\u001b[32m      5\u001b[39m artistes = { k:v \u001b[38;5;28;01mfor\u001b[39;00m k,v \u001b[38;5;129;01min\u001b[39;00m artistes.iteritems() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(v) > \u001b[32m200\u001b[39m }\n",
      "\u001b[31mNameError\u001b[39m: name 'db' is not defined"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "base_artistes = defaultdict(set)\n",
    "for k,v in db.iteritems():\n",
    "    base_artistes[v['artistes']].add(k)\n",
    "artistes = { k:v for k,v in artistes.iteritems() if len(v) > 200 }\n",
    "print('{} artistes'.format(len(artistes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ed74c05",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nltk'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnltk\u001b[39;00m\n\u001b[32m      2\u001b[39m test = \u001b[33m\"\u001b[39m\u001b[33mBonjour, je suis un texte d\u001b[39m\u001b[33m'\u001b[39m\u001b[33mexemple pour le cours d\u001b[39m\u001b[33m'\u001b[39m\u001b[33mOpenclassrooms. Soyez attentifs à ce cours !\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      4\u001b[39m nltk.word_tokenize(test)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'nltk'"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "test = \"Bonjour, je suis un texte d'exemple pour le cours d'Openclassrooms. Soyez attentifs à ce cours !\"\n",
    "\n",
    "nltk.word_tokenize(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9cd4cd4a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nltk' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m tokenizer = \u001b[43mnltk\u001b[49m.RegexpTokenizer(\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      2\u001b[39m tokenizer.tokenize(\u001b[33m\"\u001b[39m\u001b[33mBonjour, je suis un texte d\u001b[39m\u001b[33m'\u001b[39m\u001b[33mexemple pour le cours d\u001b[39m\u001b[33m'\u001b[39m\u001b[33mOpenclassrooms. Soyez attentifs à ce cours !\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'nltk' is not defined"
     ]
    }
   ],
   "source": [
    "tokenizer = nltk.RegexpTokenizer(r'\\w+')\n",
    "tokenizer.tokenize(\"Bonjour, je suis un texte d'exemple pour le cours d'Openclassrooms. Soyez attentifs à ce cours !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "121b1668",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nltk' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m tokenizer = \u001b[43mnltk\u001b[49m.RegexpTokenizer(\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfreq_stats_corpora\u001b[39m():\n\u001b[32m      4\u001b[39m     corpora = defaultdict(\u001b[38;5;28mlist\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'nltk' is not defined"
     ]
    }
   ],
   "source": [
    "tokenizer = nltk.RegexpTokenizer(r'\\w+')\n",
    "\n",
    "def freq_stats_corpora():\n",
    "    corpora = defaultdict(list)\n",
    "\n",
    "    # Création d'un corpus de tokens par artiste\n",
    "    for artiste,sentence_id in artistes.iteritems():\n",
    "        for sentence_id in sentence_id:\n",
    "            corpora[artiste] += tokenizer.tokenize(\n",
    "                                    db[sentence_id]['text'].decode('utf-8').lower()\n",
    "                                )\n",
    "\n",
    "    stats, freq = dict(), dict()\n",
    "\n",
    "    for k, v in corpora.iteritems():\n",
    "        freq[k] = fq = nltk.FreqDist(v)\n",
    "        stats[k] = {'total': len(v)} \n",
    "        \n",
    "    return (freq, stats, corpora)\n",
    "\n",
    "# Récupération des comptages\n",
    "freq, stats, corpora = freq_stats_corpora()\n",
    "df = pd.DataFrame.from_dict(stats, orient='index')\n",
    "\n",
    "# Affichage des fréquences\n",
    "df.sort(columns='total', ascending=False)\n",
    "df.plot(kind='bar', color=\"#f56900\", title='Top 50 Rappeurs par nombre de mots')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e72f9629",
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_stats_corpora():\n",
    "    corpora = defaultdict(list)\n",
    "    for artiste,sentence_ids in artistes.iteritems():\n",
    "        for sentence_id in sentence_ids:\n",
    "            corpora[artiste] += tokenizer.tokenize(\n",
    "                                    db[sentence_id]['text'].decode('utf-8').lower()\n",
    "                                )\n",
    "        \n",
    "    stats, freq = dict(), dict()\n",
    "\n",
    "    for k, v in corpora.iteritems():\n",
    "        freq[k] = fq = nltk.FreqDist(v)\n",
    "        stats[k] = {'total': len(v), 'unique': len(fq.keys())}\n",
    "\n",
    "    return (freq, stats, corpora)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57872f17",
   "metadata": {},
   "source": [
    "## TP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9899680",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5687c54b",
   "metadata": {},
   "source": [
    "Quelle est la forme du Dataframe ? \n",
    "\n",
    "Y a t-il des valeurs manquantes ou des valeurs dupliquées ? \n",
    "\n",
    "Quelles sont les colonnes qui vont nous intéresser ? \n",
    "\n",
    "Y a-t-il des données aberrantes ou des incohérences majeures dans les données ? \n",
    "\n",
    "Y a t-il des tweets anormalement longs / courts ? Peut-on les considérer comme des outliers ? \n",
    "\n",
    "Quel est le ratio tweet qui parlent de “catastrophes” / tweet normaux ?\n",
    "\n",
    "En regardant quelques tweets au hasard, peut-on deviner facilement la “target” ? \n",
    "\n",
    "Peut-on déjà détecter des “patterns” ou des mots clés dans les tweets?\n",
    "\n",
    "A votre avis quel serait l’accuracy score qu’un humain pourrait obtenir s’il prédisait  les données “à la main” ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "50dbc598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2493</th>\n",
       "      <td>3582</td>\n",
       "      <td>desolate</td>\n",
       "      <td>Macclesfield</td>\n",
       "      <td>@binellithresa TY for the follow Go To http://...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2835</th>\n",
       "      <td>4079</td>\n",
       "      <td>displaced</td>\n",
       "      <td>Oakland, CA</td>\n",
       "      <td>Historic flooding across Asia leaves hundreds ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7397</th>\n",
       "      <td>10584</td>\n",
       "      <td>windstorm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Texas Seeks Comment on Rules for Changes to Wi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3340</th>\n",
       "      <td>4784</td>\n",
       "      <td>evacuated</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#WorldNews Fallen powerlines on G:link tram: U...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182</th>\n",
       "      <td>1702</td>\n",
       "      <td>bridge%20collapse</td>\n",
       "      <td>UK</td>\n",
       "      <td>Australia's Ashes disaster - how the collapse ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3004</th>\n",
       "      <td>4317</td>\n",
       "      <td>dust%20storm</td>\n",
       "      <td>D(M)V</td>\n",
       "      <td>@RetiredFilth people in sydney woke up to the ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6728</th>\n",
       "      <td>9642</td>\n",
       "      <td>thunderstorm</td>\n",
       "      <td>South Carolina</td>\n",
       "      <td>Strong Thunderstorm 4 Miles East of Pickens Mo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2315</th>\n",
       "      <td>3324</td>\n",
       "      <td>demolished</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lol meerkat is fucked. They will get demolishe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>65</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I gained 3 followers in the last week. You? Kn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1394</th>\n",
       "      <td>2012</td>\n",
       "      <td>casualties</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Another movie theater attack..close to home th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id            keyword        location  \\\n",
       "2493   3582           desolate    Macclesfield   \n",
       "2835   4079          displaced     Oakland, CA   \n",
       "7397  10584          windstorm             NaN   \n",
       "3340   4784          evacuated             NaN   \n",
       "1182   1702  bridge%20collapse              UK   \n",
       "3004   4317       dust%20storm         D(M)V     \n",
       "6728   9642       thunderstorm  South Carolina   \n",
       "2315   3324         demolished             NaN   \n",
       "45       65             ablaze             NaN   \n",
       "1394   2012         casualties             NaN   \n",
       "\n",
       "                                                   text  target  \n",
       "2493  @binellithresa TY for the follow Go To http://...       1  \n",
       "2835  Historic flooding across Asia leaves hundreds ...       1  \n",
       "7397  Texas Seeks Comment on Rules for Changes to Wi...       0  \n",
       "3340  #WorldNews Fallen powerlines on G:link tram: U...       1  \n",
       "1182  Australia's Ashes disaster - how the collapse ...       1  \n",
       "3004  @RetiredFilth people in sydney woke up to the ...       1  \n",
       "6728  Strong Thunderstorm 4 Miles East of Pickens Mo...       1  \n",
       "2315  Lol meerkat is fucked. They will get demolishe...       0  \n",
       "45    I gained 3 followers in the last week. You? Kn...       0  \n",
       "1394  Another movie theater attack..close to home th...       1  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data/TP_analyse_donnees_textuelles/train.csv')\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "568e2b1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    4342\n",
       "1    3271\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1a0ce9b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "location\n",
       "USA                   104\n",
       "New York               71\n",
       "United States          50\n",
       "London                 45\n",
       "Canada                 29\n",
       "                     ... \n",
       "Silesia, Poland         1\n",
       "Hickville, USA          1\n",
       "New York NYC            1\n",
       "Valle Del Sol           1\n",
       "todaysbigstock.com      1\n",
       "Name: count, Length: 3341, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['location'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71ea9b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La forme du dataframe est (7613, 5)\n"
     ]
    }
   ],
   "source": [
    "print(f'La forme du dataframe est {df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1191eaf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id             0\n",
       "keyword       61\n",
       "location    2533\n",
       "text           0\n",
       "target         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df387cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32752/656283662.py:1: FutureWarning: unique with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  pd.unique(df)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['id', 'keyword', 'location', 'text', 'target', None], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.unique(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0c5b5039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a370005f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, keyword, location, text, target]\n",
       "Index: []"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1ac4c3",
   "metadata": {},
   "source": [
    "Pas de valeurs dupliquées"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44002980",
   "metadata": {},
   "source": [
    "Les colonnes qui vont nous intéresser sont keyword, location, text et target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a988c1",
   "metadata": {},
   "source": [
    "Y a-t-il des données aberrantes ou des incohérences majeures dans les données ?  Aucune idée"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033919ce",
   "metadata": {},
   "source": [
    "Y a t-il des tweets anormalement longs / courts ? Peut-on les considérer comme des outliers ? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab254fb7",
   "metadata": {},
   "source": [
    "## Transformez les données textuelles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc29f12",
   "metadata": {},
   "source": [
    "## Détectez automatiquement les sentiments des commentaires clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24f8746",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
